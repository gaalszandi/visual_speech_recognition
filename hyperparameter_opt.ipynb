{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperas.distributions import choice, uniform\n",
    "from hyperas import optim\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "CLASS_NUM = 10\n",
    "NBFRAME = 20\n",
    "#model = create_Resnet_GRU(mode='backendGRU', inputDim=64, hiddenDim=20, nClasses=CLASS_NUM, frameLen=NBFRAME, every_frame=True)\n",
    "\n",
    "def data():\n",
    "    class VideoFrameGenerator(keras.utils.Sequence):\n",
    "    '''\n",
    "        Generates video frames from frame directories\n",
    "    '''\n",
    "        def __init__(self,\n",
    "                 from_dir,\n",
    "                 rescale=1/255.,\n",
    "                 batch_size=8,\n",
    "                 shape=(100, 100, 3),\n",
    "                 nbframe=20,\n",
    "                 shuffle=False,\n",
    "                 transform:keras.preprocessing.image.ImageDataGenerator=None,\n",
    "                 grayscale=False\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Create a Video Frame Generator with data augmentation.\n",
    "        \n",
    "        Arguments:\n",
    "        - from_dir: path to the data directory where resides video frames\n",
    "        - rescale: the value for rescaling the images\n",
    "        - batch_size: number of videos to generate in a step\n",
    "        - shape: the shape of the result images\n",
    "        - nbframe: number of frames per video\n",
    "        - shuffle: flag to shuffle data at start and after each epoch\n",
    "        - transform: a keras ImageGenerator configured with random transformations\n",
    "            to apply on each frame\n",
    "        - grayscale: flag to convert images to grayscale or not\n",
    "        \"\"\"\n",
    "\n",
    "            self.from_dir = from_dir\n",
    "            self.rescale = rescale\n",
    "            self.nbframe = nbframe\n",
    "            self.batch_size = batch_size\n",
    "            self.target_shape = shape\n",
    "            self.shuffle = shuffle\n",
    "            self.transform = transform\n",
    "            self.grayscale = grayscale\n",
    "        \n",
    "            self.classes = []\n",
    "            self.files = []\n",
    "            self.class_indices = {}\n",
    "\n",
    "            self._current = 0\n",
    "        \n",
    "            self.__filecount = 0\n",
    "            self.__get_all_files()\n",
    "\n",
    "            print(\"\\nTotal data: %d classes for %d files for %s\" % (\n",
    "                len(self.classes),\n",
    "                len(self.files),\n",
    "                os.path.basename(self.from_dir)))\n",
    "    \n",
    "        \n",
    "        def __len__(self):\n",
    "        \"\"\" Length of the generator\n",
    "         It gives the number of loop to do. You can use it as\n",
    "        `step_per_epoch` or `validation_step` for `model.fit_generator` parameters.\n",
    "        \"\"\"\n",
    "            return self.__filecount//self.batch_size\n",
    "\n",
    "        def __iter__(self):\n",
    "              return self\n",
    "\n",
    "        def __next__(self):\n",
    "            return self.next()\n",
    "    \n",
    "        def next(self):\n",
    "          \"\"\" Return next element\"\"\"\n",
    "          elem = self[self._current]\n",
    "              self._current += 1\n",
    "            if self._current == len(self):\n",
    "                self._current = 0\n",
    "                self.on_epoch_end()\n",
    "            return elem\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\" Generator needed method - return a batch of `batch_size` video frames\n",
    "        \"\"\"\n",
    "\n",
    "        labels = []\n",
    "        images = []\n",
    "\n",
    "        # get the next block of files (it contains a batchsize of the video frames)\n",
    "        frame_dirs = self.files[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        for dir in frame_dirs:\n",
    "          # get classname from path\n",
    "          label_name = self._get_classname(dir)\n",
    "\n",
    "          # check if class name is valid\n",
    "          label = np.zeros(len(self.classes))\n",
    "          if label_name not in self.class_indices.keys():\n",
    "            print(f'ERROR: {label_name} not in class labels.')\n",
    "            continue\n",
    "          \n",
    "          # get the id of the class\n",
    "          col = self.class_indices[label_name]\n",
    "          label[col] = 1.\n",
    "\n",
    "          # get preprocessed frames for the actual video\n",
    "          frames = self.__readframe(dir)\n",
    "\n",
    "          if frames is None:\n",
    "            continue\n",
    "\n",
    "          # use data augmentation\n",
    "          frames = self.__data_aug(frames)\n",
    "        \n",
    "          # add the sequence in batch\n",
    "          images.append(frames)\n",
    "          labels.append(label)\n",
    "\n",
    "        return np.array(images), np.array(labels)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\" When epoch has finished, random shuffle images in memory \"\"\"\n",
    "\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.files)\n",
    "\n",
    "    def _get_classname(self, video: str) -> str:\n",
    "      \"\"\" Find classname from video fraem dir path \"\"\"\n",
    "\n",
    "      classname = os.path.basename(os.path.dirname(video))\n",
    "      return classname\n",
    "    \n",
    "    def __get_all_files(self):\n",
    "        \"\"\" List and store images path in memory \"\"\"\n",
    "        # get classes and sort them in ABC order\n",
    "        self.classes = glob.glob(os.path.join(self.from_dir, '*'))\n",
    "        self.classes = sorted([os.path.basename(c) for c in self.classes])\n",
    "\n",
    "        # create label indexes for classes\n",
    "        self.class_indices = dict(zip(self.classes, range(len(self.classes))))\n",
    "\n",
    "        # count all video file dirs\n",
    "        self.__filecount = len(glob.glob(os.path.join(self.from_dir, '*/*')))\n",
    "        \n",
    "        for classname in self.classes:\n",
    "            # print('\\n', classname)\n",
    "\n",
    "            # list video file dirs for classes\n",
    "            videos = glob.glob(os.path.join(self.from_dir, classname, '*'))\n",
    "\n",
    "            self.files += videos\n",
    "\n",
    "        # shuffle files\n",
    "        random.shuffle(self.files)\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def __readframe(self, frame_dir):\n",
    "      \"\"\"Read and preprocess frames from directory\"\"\"\n",
    "      frames = []\n",
    "\n",
    "      # read frame images\n",
    "      files = glob.glob(os.path.join(frame_dir, '*'))\n",
    "      for f in files:\n",
    "        frame = cv.imread(f)\n",
    "        frame = cv.cvtColor(frame, cv.COLOR_BGR2RGB)\n",
    "        frame = cv.resize(frame, self.target_shape[:2])\n",
    "        if self.grayscale:\n",
    "          frame = cv.cvtColor(frame, cv.COLOR_RGB2GRAY) \n",
    "\n",
    "        frame = img_to_array(frame) * self.rescale\n",
    "        frames.append(frame)\n",
    "      \n",
    "      if len(frames)==0:\n",
    "        print(\"ERROR: not found frames\\n\")\n",
    "        return None\n",
    "\n",
    "      else:\n",
    "        \n",
    "        # use padding to create a self.nbframes length of images\n",
    "        frames = pad_sequences([frames], padding=\"post\", maxlen=self.nbframe, dtype=float, truncating=\"post\")[0]\n",
    "\n",
    "        # add frames in memory\n",
    "        if len(frames) == self.nbframe:\n",
    "            return frames\n",
    "            \n",
    "        else:\n",
    "            print('\\n%s has not enough frames ==> %d' % (frame_dir, len(frames)))\n",
    "            return None\n",
    "            \n",
    "    def __data_aug(self, frames):\n",
    "        \"\"\" Make random transformation based on ImageGenerator arguments\"\"\"\n",
    "        T = None\n",
    "        if self.transform is not None:\n",
    "          # get random transform from generator\n",
    "            T = self.transform.get_random_transform(self.target_shape[:2])\n",
    "        \n",
    "        result = frames\n",
    "        if T is not None:\n",
    "          # apply transformation\n",
    "          result = [self.transform.apply_transform(frame, T) for frame in frames]\n",
    "\n",
    "        return np.array(result)\n",
    "  \n",
    "    \n",
    "  NBFRAME = 20\n",
    "  TARGET_SIZE = 100\n",
    "  BSIZE = 32\n",
    "  DATA_AUG = False\n",
    "  TO_GRAYSCALE = True\n",
    "\n",
    "  if DATA_AUG:\n",
    "    data_aug = keras.preprocessing.image.ImageDataGenerator(\n",
    "      horizontal_flip=True,\n",
    "      rotation_range=8,\n",
    "      height_shift_range=.2)\n",
    "  else:\n",
    "    data_aug = None\n",
    "\n",
    "  TRAIN_DIR = '/content/visual_speech_recognition/dataset10/train'\n",
    "  VAL_DIR = '/content/visual_speech_recognition/dataset10/val'\n",
    "  TEST_DIR = '/content/visual_speech_recognition/dataset10/test'\n",
    "\n",
    "\n",
    "  train_gen = VideoFrameGenerator(from_dir = TRAIN_DIR,\n",
    "                 rescale=1/255.,\n",
    "                 batch_size=BSIZE,\n",
    "                 shape=(TARGET_SIZE, TARGET_SIZE, 1 if TO_GRAYSCALE else 3),\n",
    "                 nbframe=NBFRAME,\n",
    "                 shuffle=True,\n",
    "                 grayscale = TO_GRAYSCALE,\n",
    "                 transform=data_aug)\n",
    "\n",
    "\n",
    "  test_gen = VideoFrameGenerator(from_dir = TEST_DIR,\n",
    "                 rescale=1/255.,\n",
    "                 batch_size=1,\n",
    "                 shape=(TARGET_SIZE, TARGET_SIZE, 1 if TO_GRAYSCALE else 3),\n",
    "                 nbframe=NBFRAME,\n",
    "                 shuffle=False,\n",
    "                 grayscale = TO_GRAYSCALE)\n",
    "  \n",
    "  val_gen = VideoFrameGenerator(from_dir = VAL_DIR,\n",
    "                 rescale=1/255.,\n",
    "                 batch_size=1,\n",
    "                 shape=(TARGET_SIZE, TARGET_SIZE, 1 if TO_GRAYSCALE else 3),\n",
    "                 nbframe=NBFRAME,\n",
    "                 shuffle=False,\n",
    "                 grayscale = TO_GRAYSCALE,\n",
    "                 transform=data_aug)\n",
    "\n",
    "  return train_gen,val_gen, test_gen\n",
    "\n",
    "def create_model(train_gen, val_gen):\n",
    "\n",
    "  CLASS_NUM = 10\n",
    "\n",
    "  import tensorflow as tf\n",
    "  from tensorflow.keras.layers import Input, Dense, GRU, GlobalAveragePooling2D, MaxPooling1D, Lambda, Bidirectional\n",
    "  from tensorflow.keras.layers import MaxPooling3D, ZeroPadding3D, Conv3D, Conv1D, Activation, BatchNormalization, Dropout\n",
    "  from keras.optimizers import Adam, SGD, RMSprop\n",
    "  from tensorflow.keras import Model, Sequential\n",
    "  from classification_models.keras import Classifiers\n",
    "  from hyperas.distributions import choice, uniform\n",
    "  from hyperas import optim\n",
    "\n",
    "  # hyper parameter ranges\n",
    "  activation = {{choice(['relu', 'elu','tanh'])}}\n",
    "  dropout = {{uniform(0, 0.4)}}\n",
    "  optimizer = {{choice(['rmsprop', 'adam', 'sgd'])}}\n",
    "  hiddenDim = {{choice([20,50,80])}}\n",
    "  inputDim = {{choice([32,64,128])}}\n",
    "\n",
    "  def GRU(x, hidden_size):\n",
    "\n",
    "    # in case of GRU add reset_after=False parameter\n",
    "    out = Bidirectional(keras.layers.GRU(hidden_size, return_sequences=True, kernel_initializer='Orthogonal', reset_after=False, name='gru1'), merge_mode='concat')(x)\n",
    "    out = Bidirectional(keras.layers.GRU(hidden_size, return_sequences=False, kernel_initializer='Orthogonal', reset_after=False, name='gru2'), merge_mode='concat')(out)\n",
    "    \n",
    "    return out\n",
    "\n",
    "  def create_Resnet_GRU(mode,  nClasses, frameLen,activation, dropout, optimizer,input_shape=(NBFRAME,TARGET_SIZE,TARGET_SIZE,1),\n",
    "                        every_frame=True, hiddenDim=hiddenDim, inputDim = inputDim):\n",
    "    frontend3D = Sequential([\n",
    "                ZeroPadding3D(padding=(2, 3, 3)),\n",
    "                Conv3D(32, kernel_size=(5, 7, 7), strides=(1, 2, 2), padding='valid', use_bias=False),\n",
    "                BatchNormalization(),\n",
    "                Activation(activation),\n",
    "                ZeroPadding3D(padding=((0, 4, 8))),\n",
    "                MaxPooling3D(pool_size=(1, 2, 3), strides=(1, 1, 2))\n",
    "                ])\n",
    "  \n",
    "    # for temporal convolution\n",
    "    backend_conv1 = Sequential([\n",
    "            Conv1D(2*inputDim, 5, strides=2, use_bias=False),\n",
    "            BatchNormalization(),\n",
    "            Activation(activation),\n",
    "            MaxPooling1D(2, 2),\n",
    "            Conv1D(4*inputDim, 5, strides=2, use_bias=False),\n",
    "            BatchNormalization(),\n",
    "            Activation(activation),\n",
    "            ])\n",
    "  \n",
    "    # for temporal convolution\n",
    "    backend_conv2 = Sequential([\n",
    "            Dense(inputDim),\n",
    "            BatchNormalization(),\n",
    "            Activation(activation),\n",
    "            Dense(nClasses)\n",
    "            ])\n",
    "  \n",
    "    # -----------------------------------------------------------------\n",
    "    # creating the model\n",
    "    input_frames = Input(shape=input_shape, name='frames_input')\n",
    "    x = frontend3D(input_frames)\n",
    "\n",
    "    # reshape output for the input of Resnet 2D\n",
    "    x = Lambda(lambda x : tf.reshape(x, [-1, int(x.shape[2]), int(x.shape[3]), int(x.shape[4])]), name='lambda2')(x)\n",
    "\n",
    "    channels = int(x.shape[-1])\n",
    "  \n",
    "    # get resnet model\n",
    "    ResNet18, preprocess_input = Classifiers.get('resnet18')\n",
    "    resnet18 = ResNet18((None, None, channels), weights=None, include_top=False)\n",
    "\n",
    "    x = resnet18(x)\n",
    "\n",
    "    # Flatten with global average pooling  for the input of the dense layer\n",
    "    x = GlobalAveragePooling2D(name='global_avgpool_resnet')(x)\n",
    "    x = Dense(inputDim, name='dense_resnet')(x)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = BatchNormalization(name='bn_resnet')(x)\n",
    "\n",
    "    if mode == 'temporalConv':\n",
    "      x = Lambda(lambda x : tf.reshape(x, [-1, frameLen, inputDim]), name='lambda3')(x)   #x.view(-1, frameLen, inputDim)\n",
    "\n",
    "      x = Lambda(lambda x : tf.transpose(x, [0, 2, 1]), name='lambda4')(x)   #x.transpose(1, 2)\n",
    "      x = backend_conv1(x)\n",
    "      x = Lambda(lambda x : tf.reduce_mean(x, 2), name='lambda5')(x)\n",
    "      x = backend_conv2(x)\n",
    "\n",
    "    elif mode == 'backendGRU' or mode == 'finetuneGRU':\n",
    "      x = Lambda(lambda x : tf.reshape(x, [-1, frameLen, inputDim]), name='lambda6')(x)    #x.view(-1, frameLen, inputDim)\n",
    "\n",
    "      # add memory cells to the network (GRU or LSTM)\n",
    "      x = GRU(x, hiddenDim)\n",
    "\n",
    "      # add the dropout layer and the last Dense layer for classification\n",
    "      if every_frame:\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Dense(nClasses, activation='softmax')(x)  # predictions based on every time step\n",
    "      else:\n",
    "        x = Dropout(dropout)(x)\n",
    "        x = Dense(nClasses, activation='softmax')(x[:, -1, :])  # predictions based on last time-step\n",
    "\n",
    "      model = Model(inputs=input_frames, outputs=x)\n",
    "\n",
    "    return model\n",
    "\n",
    "  # construct the model\n",
    "  \n",
    "  model = create_Resnet_GRU(mode='backendGRU', inputDim=inputDim,hiddenDim = hiddenDim,  nClasses=CLASS_NUM, frameLen=NBFRAME, every_frame=True,\n",
    "                            activation = activation, dropout = dropout, optimizer = optimizer)\n",
    "  \n",
    "  # choose the optimizer according to the given string\n",
    "  if optimizer == \"rmsprop\":\n",
    "    optim = keras.optimizers.RMSprop(learning_rate = 0.001, momentum = 0.9)\n",
    "  elif optimizer == \"adam\":\n",
    "    optim = keras.optimizers.Adam(learning_rate = 0.001)\n",
    "  else:\n",
    "    optim = keras.optimizers.SGD(learning_rate = 0.001, momentum = 0.9)\n",
    "\n",
    "\n",
    "  model.compile(optimizer=optim,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "\n",
    "  callbacks = [keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=3, verbose=0)]\n",
    "  \n",
    "  result = model.fit_generator(train_gen,\n",
    "                epochs=40,\n",
    "                verbose=2,                \n",
    "                validation_data=val_gen,\n",
    "                callbacks = callbacks,\n",
    "                shuffle=True)\n",
    "  \n",
    "  acc = np.amax(result.history['val_accuracy']) \n",
    "\n",
    "  #dropout, activation, optimizer, n_batch\n",
    "  with open('/content/drive/MyDrive/hyperas-sr-log.csv', 'a') as csv_file:\n",
    "    csv_file.write(str(dropout) + ';')\n",
    "    csv_file.write(str(activation) + ';')\n",
    "    csv_file.write(str(optimizer) + ';')\n",
    "    csv_file.write(str(hiddenDim)+';')\n",
    "    csv_file.write(str(inputDim)+';')\n",
    "    csv_file.write(str(64) + ';')   \n",
    "    csv_file.write(str(acc) + '\\n')\n",
    "\n",
    "  return {'loss': -acc, 'status': STATUS_OK, 'model':model}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize log file\n",
    "with open('/content/drive/MyDrive/hyperas-sr-log.csv', 'w') as csv_file:\n",
    "  csv_file.write('dropout' + ';')\n",
    "  csv_file.write('activation' + ';')\n",
    "  csv_file.write('optimizer' + ';')\n",
    "  csv_file.write('hiddenDim' + ';')\n",
    "  csv_file.write('inputDim' + ';')\n",
    "  csv_file.write('n_batch' + ';') \n",
    "  csv_file.write('acc' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperas\n",
    "from hyperopt import Trials, STATUS_OK, tpe\n",
    "from hyperas import optim\n",
    "from hyperas.distributions import choice, uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_run, best_model = optim.minimize(\n",
    "     model=create_model,\n",
    "     data=data,\n",
    "     algo=tpe.suggest,\n",
    "     max_evals=100,\n",
    "     notebook_name='training_script',\n",
    "     trials= Trials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "log_file = pandas.read_csv('/content/drive/MyDrive/hyperas-sr-log.csv', delimiter=';')\n",
    "\n",
    "best10 = log_file.sort_values(by=['acc'], ascending=False).head(n=10)\n",
    "best10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "max_val_acc = log_file.groupby(['hiddenDim', 'optimizer']).max()\n",
    "max_val_acc = max_val_acc.unstack()[['acc']]\n",
    "sns.heatmap(max_val_acc.acc, annot=True, fmt='.4g');\n",
    "\n",
    "b, t = plt.ylim()\n",
    "b += 0.5\n",
    "t -= 0.5\n",
    "plt.ylim(b, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_val_acc = log_file.groupby(['inputDim', 'optimizer']).max()\n",
    "max_val_acc = max_val_acc.unstack()[['acc']]\n",
    "sns.heatmap(max_val_acc.acc, annot=True, fmt='.4g');\n",
    "\n",
    "b, t = plt.ylim()\n",
    "b += 0.5\n",
    "t -= 0.5\n",
    "plt.ylim(b, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
